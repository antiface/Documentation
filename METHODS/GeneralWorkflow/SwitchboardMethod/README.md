## THE SWITCHBOARD METHOD OF PROJECT-BASED, SERIAL ART PRODUCTION

*"Work Efficiency At The Speed of Thought"*

*2023-11-29 12:10:08*

__*The Switchboard Method:*__
* Take __*n*__ number of tasks;
* Choose one task at a time, work on it for approximately 15 minutes, then __SWITCH TASKS__;
* Continue doing this continuously throughout the day, switching tasks every 5-10 or 15 minutes;
* Switch tasks __*pseudo-randomly*__, that is, choose whatever task is most __*immediate*__;
* Choose whatever tasks is most relevant to the given time;
* Choose tasks that are more __*ready-to-hand*__ either physically *proximate* or else *close* to you in your *cognitive space*, *emotional space*, your __*Fields of Experience*__ or __*Fields of Discourse*__;
* Act as though you were a __MECHANICAL TURK__ at Amazon;
* You will achieve more efficiency this way;
* Take an example. Say someone writes 1 novel in 1 notebook;
* Now you write 12 novels in 12 notebooks, except you use the __SWITCHBOARD METHOD__;
* The other person might finish their 1 novel in __*x amount of time*__;
* You will finish in __*x+y amount of time*__, __*y*__ being a constant;
* It will take you a little more time to write 12 novels across 12 notebooks instead of 1 across 1, but at the end of __*x+y time*__, you will have written __12 NOVELS INSTEAD OF 1__;
* The __SWITCHBOARD METHOD__ is essentially a __*NON-LINEAR METHOD OF WORK ORGANIZATION*__ and can provide *Great Efficiencies in Time* (awaiting *mathematical proof*);

*2023-11-29 19:45:22*

* I am told this is the __*assignment problem*__ in theoretical computer science, but usually you have __n agents__ to whom you must assign __m number of tasks__;
* In my case, there are only __n tasks__ and __1 agent__;
* All that's really important here is the decision problem and efficient allocation of resources;
* You would normally look at costs and so forth, cost functions, etc.;
* Thats not my problem, though; I got rid of the decision problem and saved at least __1 bit__;
* It might not seem like a lot, yet computationally, with over __100 projects__ still actively running in my *Art Operation*, I needed to save *as many bits as possible*;
* I don't *decide* what task to work on; I tackle whatever is most __proximate/immediate/ready-to-hand__;
* It doesn't matter what it is,it will absolutely be an __enriching,learning experience__;
* Randomized task assignment just seems optimal to me; I'm able to maintain over 100 complex, interdisciplinary art-research projects, and I'm a __*One-Man Shop*__, a single art operator at the __*Art Operation @ The Historiotheque*__;
* More on this later; this is based on the research for a new project, and series of series, I started earlier in the year, called __*NOISE IN THE WORKSPACE*__;
* The first series was called __*SPACE NOISE INJECTION*__ and, you see, while the first series is still only beginning, I started the second series of experiments, called __*RANDOMIZED EXPERIMENTAL PARAMETERS*__;
* After just a few months, I have enough research and experimental data to write a PhD thesis in __interruption science__;

- - - - - - - -
![WORKSPACE STACKS 2024](https://historiotheque.files.wordpress.com/2023/12/workspace_stacks_2024d_signed_600px_450px.png)

*2023-12-04 03:17:26*
* One of the ways this *Method* works is by removing *waiting-times*;
* One does not spend any significant amount of times either *Deciding* what tasks to tackle __OR__ any significant amount of time *building up complex mental abstractions*, which software developers often have to do in the course of any given period of __*Deep Work*__;
* I merely look at the *Surface of the Workspace* and choose what is most *proximate/immediate*;
* This *literally* means looking around the __*Studio Space @ The Historiotheque*__ and choosing whatever is *nearest in time and space*;
* I realize that the *3D Surface of the Workspace* is where I get most of my new ideas, from actually *working in the Historioteque AND in the Archive*;
* It's where I came up with the concept of *Geogrammar or Geogrammatical Forms*, as __*floating land-masses*__, as portrayed in my novelistic phenomenology __*The History-Project*__ as __*Crackland, the Land of Fissures*__ and as __*Antiface-Cloud*__ in my sequel __*The Archives-Project*__;
* The so-called *land-masses* or *fragments* are really the __*exposed surfaces of the Stacks*__ (SEE: *The Stacks-Project*);
* Each of these "Stacks" are *built-up* over time as *sedimentary layers or through a sedimentation process*;
* I continuously *Survey* the top-post surfaces of these many *Stacks* and make *mental links* or __*REFCARDS*__ which I file in my *Inner Refcards-System*, my __*DATABASE-OF-IMAGES*__ (SEE: *Database Arts*);
* SEE: Images below, of the *3D Workspace as Abstract Cartography* (seen from above) and two diagrams of __*THE SWITCHBOARD METHOD*__ as well as one for *The Stacks-Project*;

![DELTA WORKSPACE](https://historiotheque.files.wordpress.com/2023/12/delta_workspace_accessed_04dec23a-16h38a_600px_450px.png)

![THE SWITCHBOARD METHOD](https://historiotheque.files.wordpress.com/2023/12/the_switchboard_method_accessed_04dec23a-16h47a_600px_wide.png)

![THE STACKS-PROJECT](https://historiotheque.files.wordpress.com/2023/12/the_stacks_project_accessed_04dec23a-16h48b_600px_wide.png)

*2023-12-06 16:39:10*

* I also use __*THE SWITCHBOARD METHOD*__ in my __*RESEARCH PROCESS*__, since I am an interdisciplinary art-researcher;
* What I do here is I aim for __*COMPLETE UNDERSTANDING*__, not merely *passing understanding*;
* What I do is follow *my heart & soul*, I only read what is *most relevant* to my current, most fundamental experience of the world;
* For instance, I'm currently reading a book about the *topological foundations of painting* because it concords nicely with what I'm experiencing these days as a professional painter;
* But then, I also finished reading a short book by Sigmund Freud on *The Uncanny* (*"L'inquiétante étrangeté"*);
* I am maybe reading 20 books at the same time, and surprisingly I don't get lost, thanks both to my *prodigious memory* AND *my meticulous note-taking and organizing of learning materials or __reference materials or REFMATS__*;
* However, like in the rest of __*THE SWITCHBOARD METHOD*__, I rapidly oscillate between reading material, always following the __*DIRECTION AND PACE*__ of what's in *my heart & soul*;
* So for every page or less or at most 2-3 pages that I read, I stop and take ample notes, i.e. audio notes and physical notes (*Writing*) in notebooks or on *Index Cards* (SEE: __*REFCARDS*__);
* Then I introspect and self-reflect, contemplate, to make sure *I actually understand what I'm reading*;
* This can take anywhere from minutes, hours, days, to weeks, months, and even years;
* Some things that I was reading 20+ years ago, I'm only just beginning to understand __*TODAY*__; it takes *that long*;
* Anyhow, I rapidly oscillate from book to book, from website to website, and in my research online, I use a variation on the *Switchboard Method*;
* I do what I have elsewhere called a *WikiWalk*;
* That is to say, I open up a *web resource* and begin reading it, and I open up each new *relevant hyperlink* into a new tab in my web browser;
* When I have up to 20-30 tabs open in the browser, to save on *RAM*, I use a *browser extension* that *saves a list of all open tabs and collapses the tabs*;
* I then copy the list of tabs on my computer in a .txt file that acts as a __*LOG*__ and I also copy a version of it in a *Gist File* on GitHub's *Gist Service*;
* I then back up all my notes and logs in the cloud as well as on an *external hard-drive*;
* I do this continuously throughout the day, when I'm not working on art, i.e. painting and music and novel-writing;
* Do I ever take breaks? Of course, I do. I'm constantly taking breaks, every 5 or 10-15, 20 minutes tops;
* I find that I get much more done throughout the day when I do things this way;
* So to recap, while I'm reading books and web resources, PDFs and so forth, I'm constantly *switching* from one to the other;
* I'll open up a video, watch 5 minutes, then open up another video, watch 3 minutes, then search for someone's name online that was mentioned in a video, etc., etc.; you get the *gist*;
* I work very rapidly, *at the speed of thought*, constantly logging, documenting, taking notes, and publishing everything online in the manner of __*CONTINUOUS DELIVERY*__;
* The *most important part of this process*, I think, is *To Ensure Correct and Complete Understanding of The Reference Materials* (__*"#REFMATS"*__);
* I can't stress this enough, how it's important to a) follow what is in my heart & soula nd b) work towards *COMPLETE UNDERSTANDINGS*, however long it takes, years and decades if necessary;
* Then I log, document, organize and publish everything online *For Future Reference*;
* Another important part is how I organize my notes;
* Simply put, and I can elaborate on this *Elsewhere*, I have a *running log* where I post everything, my conversations, citations from works online and in PDFs, etc., and every day I go through it and copy out *particularly pertinent materials* and create __*new .txt files*__ with descriptive titles, with the content that I found particularly *interesting*;
* I also constantly go through *My Old Notes* and copy out relevant materials and create new files and post them in the new files;
* Every year, also, I have a new folder in my main __*Document folder*__ called, for instance, just __*2023*__, where I put absolutely everything for that given year;
* I call it my __*Bin-Drive or B:DRIVE*__, where I put absolutely everything;
* In any case, as I *work IN the Archive*, I go through *old notes* and when a note is particularly relevant or interesting, *I COPY THE ENTIRE NOTE INTO THE NEW YEARLY FOLDER*;
* So things are constantly being __*DUPLICATED*__, but this is in-line with my concept, and implementation, of __*REDUNDANCY IN MY ART-RESEARCH PRACTICE*__;
* Web sites/web resources in my *logged tab-sets* too get duplicated, but I find it creates a nice *graph or network of tab-sets* that I like to also go through and pick out what is most relevant or interesting; (SEE: I speak of __*redundancy in my methods*__ in these following __*General Workflow Methods*__: [Breadcrumbs](https://github.com/antiface/Documentation/tree/master/METHODS/GeneralWorkflow/Breadcrumbs), [Daypaths](https://github.com/antiface/Documentation/tree/master/METHODS/GeneralWorkflow/Daypaths), [Timestamps](https://github.com/antiface/Documentation/tree/master/METHODS/GeneralWorkflow/Timestamps), and [RefinementProcess](https://github.com/antiface/Documentation/tree/master/METHODS/GeneralWorkflow/RefinementProcess);

*2023-12-14 05:26:10*

> Single-machine scheduling or single-resource scheduling is an optimization problem in computer science and operations research. We are given n jobs J1, J2, ..., Jn of varying processing times, which need to be scheduled on a single machine, in a way that optimizes a certain objective, such as the throughput.
>
> Single-machine scheduling is a special case of identical-machines scheduling, which is itself a special case of optimal job scheduling. Many problems, which are NP-hard in general, can be solved in polynomial time in the single-machine case. (Ref. [Single-machine scheduling - Wikipedia](https://en.wikipedia.org/wiki/Single-machine_scheduling))

- - - - - - - - -
> Optimal job scheduling is a class of optimization problems related to scheduling. The inputs to such problems are a list of jobs (also called processes or tasks) and a list of machines (also called processors or workers). The required output is a schedule – an assignment of jobs to machines. The schedule should optimize a certain objective function. In the literature, problems of optimal job scheduling are often called machine scheduling, processor scheduling, multiprocessor scheduling, or just scheduling. (Ref. [Optimal job scheduling - Wikipedia](https://en.wikipedia.org/wiki/Optimal_job_scheduling))
- - - - - - - - -
> In mathematical optimization and decision theory, a loss function or cost function (sometimes also called an error function) is a function that maps an event or values of one or more variables onto a real number intuitively representing some "cost" associated with the event. An optimization problem seeks to minimize a loss function. An objective function is either a loss function or its opposite (in specific domains, variously called a reward function, a profit function, a utility function, a fitness function, etc.), in which case it is to be maximized. The loss function could include terms from several levels of the hierarchy. (Ref. [Loss function - Wikipedia](https://en.wikipedia.org/wiki/Loss_function))
- - - - - - - - -
> The assignment problem is a fundamental combinatorial optimization problem. In its most general form, the problem is as follows:
> 
> The problem instance has a number of agents and a number of tasks. Any agent can be assigned to perform any task, incurring some cost that may vary depending on the agent-task assignment. It is required to perform as many tasks as possible by assigning at most one agent to each task and at most one task to each agent, in such a way that the total cost of the assignment is minimized. (Ref. [Assignment problem - Wikipedia](https://en.wikipedia.org/wiki/Assignment_problem))
- - - - - - - - - -

### [BACK TO DOCUMENTATION / MEHODS / GENERAL WORKFLOW](https://github.com/antiface/Documentation/tree/master/METHODS/GeneralWorkflow)
## [BACK TO INDEX OF REPOSITORIES](https://github.com/antiface/Index)

[A.G. (c) 2024. ![A.G. (c) 2024. All Rights Reserved](https://historiotheque.files.wordpress.com/2016/11/ag_signature_official_2015_50px_cropped.jpg) All Rights Reserved.](http://alexgagnon.com)
